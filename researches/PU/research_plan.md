# üìä –ü–ª–∞–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è PU Learning (Positive-Unlabeled Learning)

> **–í–µ—Ä—Å–∏—è**: 1.0  
> **–î–∞—Ç–∞**: 2024  
> **–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞**: DmDSLab

---

## üìå –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
2. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö](#1-–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–∏-–æ–±–∑–æ—Ä-–¥–∞–Ω–Ω—ã—Ö)
3. [–û–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞](#2-–æ–ø–∏—Å–∞–Ω–∏–µ-–º–µ—Ç–æ–¥–æ–≤-–∞–Ω–∞–ª–∏–∑–∞)
4. [–ë–µ–π–∑–ª–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ](#3-–±–µ–π–∑–ª–∞–π–Ω-–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ-–±–µ–∑-pu-–º–µ—Ç–æ–¥–æ–≤)
5. [–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã PU](#4-–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ-–º–µ—Ç–æ–¥—ã-pu-learning)
6. [–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã PU](#5-—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ-–∏-–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ-–º–µ—Ç–æ–¥—ã-pu)
7. [–ü–ª–∞–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤](#6-–ø–ª–∞–Ω-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
8. [–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã](#7-–æ–∂–∏–¥–∞–µ–º—ã–µ-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã-–∏-–≤—ã–≤–æ–¥—ã)
9. [–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è](#8-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã-–∏-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)

---

## üéØ –í–≤–µ–¥–µ–Ω–∏–µ

### –ß—Ç–æ —Ç–∞–∫–æ–µ PU Learning?

**PU Learning** ‚Äî —ç—Ç–æ –ø–∞—Ä–∞–¥–∏–≥–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –≥–¥–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞:
- ‚úÖ **P** (Positive) ‚Äî —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
- ‚ùì **U** (Unlabeled) ‚Äî –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã (—Å–æ–¥–µ—Ä–∂–∞—Ç –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ, —Ç–∞–∫ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ)

### –ì–¥–µ —ç—Ç–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è?

- üè¶ **–§–∏–Ω–∞–Ω—Å—ã**: –¥–µ—Ç–µ–∫—Ü–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ (–∏–∑–≤–µ—Å—Ç–Ω—ã —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏)
- üè• **–ú–µ–¥–∏—Ü–∏–Ω–∞**: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π 
- üõí **E-commerce**: —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
- üîí **–ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ–≥–æ –ü–û

### –¶–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

> **–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤ PU Learning, —Å—Ä–∞–≤–Ω–∏—Ç—å –∏—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –∏ –≤—ã—è–≤–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞—á.**

---

## 1. üìÅ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö

### 1.1 –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö

- üóÑÔ∏è **UCI Dataset Manager** –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ DmDSLab
- üìä –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
- üîÑ –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### 1.2 –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------|
| üìè **–†–∞–∑–º–µ—Ä** | 1,000 ‚Äî 100,000 –ø—Ä–∏–º–µ—Ä–æ–≤ |
| üî¢ **–ü—Ä–∏–∑–Ω–∞–∫–∏** | 10 ‚Äî 500 |
| üéØ **–¢–∏–ø –∑–∞–¥–∞—á–∏** | –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è |
| üåà **–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ** | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ |

### 1.3 –°–∏–º—É–ª—è—Ü–∏—è PU —Å—Ü–µ–Ω–∞—Ä–∏—è

#### üé≤ –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è PU –¥–∞–Ω–Ω—ã—Ö:

1. **–°–ª—É—á–∞–π–Ω—ã–π –æ—Ç–±–æ—Ä** (SCAR ‚Äî Selected Completely At Random)
   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ç–∫–∏: `P(s=1|y=1) = Œ±`
   - –í–∞—Ä–∏–∞–Ω—Ç—ã Œ±: `[0.1, 0.3, 0.5, 0.7]`

2. **–û—Ç–±–æ—Ä —Å —Å–º–µ—â–µ–Ω–∏–µ–º** (SAR ‚Äî Selected At Random)
   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: `P(s=1|x,y=1)`
   - –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

### 1.4 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```
Pipeline:
‚îú‚îÄ‚îÄ üìä –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚îú‚îÄ‚îÄ üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
‚îú‚îÄ‚îÄ ‚úÇÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏–π (60/20/20)
‚îî‚îÄ‚îÄ üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
```

---

## 2. üìà –û–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞

### 2.1 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

#### 2.1.1 üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤

- **–ì—Ä–∞—Ñ–∏–∫**: –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ vs PU —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
- **–ú–µ—Ç—Ä–∏–∫–∞**: `KL(P_true || P_observed)` ‚Äî KL-–¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: 
  - KL < 0.1 ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–∫–∞–∂–µ–Ω–∏–µ
  - KL > 0.5 ‚Äî —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å–∫–∞–∂–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

#### 2.1.2 üó∫Ô∏è t-SNE/UMAP –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

- **–ì—Ä–∞—Ñ–∏–∫**: 2D –ø—Ä–æ–µ–∫—Ü–∏—è —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
  - üü¢ P (—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ)
  - üü° U (–Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ)
  - üî¥ –°–∫—Ä—ã—Ç—ã–µ N (ground truth)
- **–ú–µ—Ç—Ä–∏–∫–∏**: 
  - Silhouette score ‚àà [-1, 1]
  - Davies-Bouldin index (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ

#### 2.1.3 üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

- **–ì—Ä–∞—Ñ–∏–∫**: Box plots —Ç–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- **–ú–µ—Ç—Ä–∏–∫–∏**: 
  - Information Gain
  - Gini importance
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 2.2 –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏

#### 2.2.1 üìê –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –§–æ—Ä–º—É–ª–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ PU |
|---------|---------|----------|-----------------|
| **Accuracy** | `(TP+TN)/(TP+TN+FP+FN)` | –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å | ‚ö†Ô∏è –ú–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤–∞ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ |
| **Balanced Accuracy** | `(TPR+TNR)/2` | –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º | ‚úÖ –£—Å—Ç–æ–π—á–∏–≤–∞ –∫ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É |
| **Precision** | `TP/(TP+FP)` | –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π | üéØ –ö—Ä–∏—Ç–∏—á–Ω–∞, –∫–æ–≥–¥–∞ –≤–∞–∂–Ω—ã false positives |
| **Recall (TPR)** | `TP/(TP+FN)` | –ü–æ–ª–Ω–æ—Ç–∞ –ø–æ–∏—Å–∫–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö | üîç –í–∞–∂–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö P |
| **Specificity (TNR)** | `TN/(TN+FP)` | –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö | ‚≠ê –ö–ª—é—á–µ–≤–∞—è –¥–ª—è PU |
| **F1-score** | `2√ó(P√óR)/(P+R)` | –ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ P –∏ R | ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø–æ–ª–Ω–æ—Ç—ã |
| **AUC-ROC** | –ü–ª–æ—â–∞–¥—å –ø–æ–¥ ROC | –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è | üìä –ù–µ–∑–∞–≤–∏—Å–∏–º–∞ –æ—Ç –ø–æ—Ä–æ–≥–∞ |
| **AUC-PR** | –ü–ª–æ—â–∞–¥—å –ø–æ–¥ PR | –î–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö | üéØ –ë–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∞ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ |

#### 2.2.2 üéØ PU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **PU-F1**: –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è F1 –¥–ª—è PU —Å—Ü–µ–Ω–∞—Ä–∏—è
- **œÄÃÇ (Estimated class prior)**: –û—Ü–µ–Ω–∫–∞ –∏—Å—Ç–∏–Ω–Ω–æ–π –¥–æ–ª–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö
- **MAP@k, NDCG@k**: –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è

### 2.3 –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

#### 2.3.1 üìä –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å

```python
# –ü—Ä–æ—Ü–µ–¥—É—Ä–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
1. 5-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
2. Friedman test (p < 0.05)
3. Nemenyi post-hoc test
4. 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
```

#### 2.3.2 üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

##### üéØ **Radar Chart**
- **–í–µ—Ä—à–∏–Ω—ã**: F1, Balanced Accuracy, AUC-ROC, Specificity, Recall
- **–ú–Ω–æ–≥–æ—É–≥–æ–ª—å–Ω–∏–∫–∏**: —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
- **–î–∞–Ω–Ω—ã–µ**: —Å—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

##### üî• **Heatmap –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**
- **–°—Ç—Ä–æ–∫–∏**: –º–µ—Ç–æ–¥—ã
- **–°—Ç–æ–ª–±—Ü—ã**: –º–µ—Ç—Ä–∏–∫–∏
- **–ó–Ω–∞—á–µ–Ω–∏—è**: —Å—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

##### üìä **–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è**

```python
# –í–µ—Å –¥–∞—Ç–∞—Å–µ—Ç–∞
w_i = (log(n_samples_i) √ó imbalance_ratio_i √ó sqrt(n_features_i)) / Œ£w_j

# –°—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
M_method = Œ£(w_i √ó m_i)
```

##### üìà **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏**
- **Box plots**: –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º
- **Scatter plots**: –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–º–µ—Ç–æ–¥ √ó –¥–∞—Ç–∞—Å–µ—Ç)
- **Critical difference –¥–∏–∞–≥—Ä–∞–º–º—ã**: —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ

#### 2.3.3 ‚ö° –ê–Ω–∞–ª–∏–∑ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

- ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- üöÄ –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
- üíæ –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- üìà –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å

---

## 3. üèÅ –ë–µ–π–∑–ª–∞–π–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ (–±–µ–∑ PU –º–µ—Ç–æ–¥–æ–≤)

### 3.1 –ù–∞–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (Treat U as N)

> **–ò–¥–µ—è**: –í—Å–µ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏

#### üõ†Ô∏è –ê–ª–≥–æ—Ä–∏—Ç–º—ã:

| –¢–∏–ø | –ê–ª–≥–æ—Ä–∏—Ç–º—ã | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|-----|-----------|-------------|
| **–õ–∏–Ω–µ–π–Ω—ã–µ** | Logistic Regression | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å |
| **–ê–Ω—Å–∞–º–±–ª–∏ –¥–µ—Ä–µ–≤—å–µ–≤** | Random Forest, ExtraTrees | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —à—É–º—É |
| **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥** | XGBoost, LightGBM, CatBoost | –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| **SVM** | RBF/Linear kernel | –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã |
| **–ù–µ–π—Ä–æ—Å–µ—Ç–∏** | MLP | –°–ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ |

### 3.2 –ü–æ–ª—É-–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ

#### üîÑ **Self-training**
```python
while confidence > threshold:
    1. –û–±—É—á–∏—Ç—å –Ω–∞ P ‚à™ pseudo_N
    2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–∞ U
    3. –î–æ–±–∞–≤–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ pseudo_N
```

#### üë• **Co-training**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ multiple views –¥–∞–Ω–Ω—ã—Ö
- –ö–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏

#### üåê **Label propagation**
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
- –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –ø–æ –≥—Ä–∞—Ñ—É

### 3.3 –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –±–µ–π–∑–ª–∞–π–Ω–∞

- üìä Confusion matrix –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Œ±
- üìà –ö—Ä–∏–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫ –æ—Ç Œ±
- üéØ –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

---

## 4. üîß –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã PU Learning

### 4.1 Two-step –º–µ—Ç–æ–¥—ã

#### 4.1.1 üïµÔ∏è **Spy technique**

```python
Algorithm:
1. –í–Ω–µ–¥—Ä–∏—Ç—å "—à–ø–∏–æ–Ω–æ–≤" (10% –æ—Ç P) –≤ U
2. –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ P vs (U ‚à™ Spies)
3. –ù–∞–π—Ç–∏ –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –Ω–∞–¥—ë–∂–Ω—ã—Ö N
4. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ P vs reliable_N
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**:
- üìä –î–æ–ª—è —à–ø–∏–æ–Ω–æ–≤: 5-15%
- üéØ –ü–æ—Ä–æ–≥ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏: 15-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å scores —à–ø–∏–æ–Ω–æ–≤

#### 4.1.2 üîç **1-DNF (1-Disjunctive Normal Form)**

- –ü–æ–∏—Å–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è **—Ç–æ–ª—å–∫–æ** –≤ P
- –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ DNF –ø—Ä–∞–≤–∏–ª
- ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: —Ç—Ä–µ–±—É–µ—Ç –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

#### 4.1.3 üìà **Roc-SVM**

- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ROC-–∫—Ä–∏–≤–æ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ—Ä–æ–≥–∞
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline SVM

### 4.2 –ú–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

#### 4.2.1 üìä **Elkan & Noto**

**–ö–ª—é—á–µ–≤–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ**: SCAR (Selected Completely At Random)

```python
# –û—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
P(y=1|x) = P(s=1|x) / c
–≥–¥–µ c = P(s=1|y=1) ‚Äî –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞
```

#### 4.2.2 ‚öñÔ∏è **Ward –º–µ—Ç–æ–¥**

- –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
- –û—Ü–µ–Ω–∫–∞ class prior —á–µ—Ä–µ–∑ EM-–∞–ª–≥–æ—Ä–∏—Ç–º
- –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

### 4.3 üå≤ Bagging-based –º–µ—Ç–æ–¥—ã

- **Bagging PU**: Bootstrap –∏–∑ P –∏ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –∏–∑ U
- **PU Random Forest**: –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –∫—Ä–∏—Ç–µ—Ä–∏—è —Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏—è
- **–ê–Ω–∞–ª–∏–∑**: out-of-bag –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

---

## 5. üöÄ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã PU

### 5.1 üìâ –ú–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ—É–Ω–∫—Ü–∏–π —Ä–∏—Å–∫–∞

#### 5.1.1 **uPU (unbiased PU)**

**–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è**: –ù–µ—Å–º–µ—â—ë–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞

```python
R_pu = œÄ_p √ó R_p + R_u - œÄ_p √ó R_p^u
–≥–¥–µ:
- œÄ_p ‚Äî –∏—Å—Ç–∏–Ω–Ω–∞—è –¥–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö
- R_p ‚Äî —Ä–∏—Å–∫ –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö
- R_u ‚Äî —Ä–∏—Å–∫ –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö
```

#### 5.1.2 **nnPU (non-negative PU)**

- –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∏—Å–∫–∞
- `R_nn = max(0, R_pu)`
- –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏

### 5.2 üß† –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è PU

#### 5.2.1 **PU-Net –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**

```python
Architecture:
‚îú‚îÄ‚îÄ Input Layer
‚îú‚îÄ‚îÄ Feature Extraction (CNN/Dense)
‚îú‚îÄ‚îÄ PU-specific Layer
‚îÇ   ‚îú‚îÄ‚îÄ Instance weighting
‚îÇ   ‚îî‚îÄ‚îÄ Adaptive thresholding
‚îú‚îÄ‚îÄ Classification Head
‚îî‚îÄ‚îÄ PU Loss Function
```

#### 5.2.2 **Self-Attention PU**

- Transformer-based –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã –¥–ª—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ attention maps

### 5.3 üé® –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã

#### 5.3.1 **PU-GAN**

```python
Components:
- Generator: G(z) ‚Üí synthetic negatives
- Discriminator: D(x) ‚Üí real/fake
- PU Classifier: C(x) ‚Üí positive/negative
```

#### 5.3.2 **VAE-PU**

- –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ P –∏ N —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –≤ latent space
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–∞ –æ–±–ª–∞—Å—Ç–∏
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏

### 5.4 üìè –ú–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

#### 5.4.1 **PU Metric Learning**

- –û–±—É—á–µ–Ω–∏–µ embedding: `f(x) ‚Üí ‚Ñù^d`
- Contrastive loss –¥–ª—è PU:
  ```python
  L = Œ£[d(f(x_p), f(x_p'))¬≤ + max(0, m - d(f(x_p), f(x_u)))¬≤]
  ```

#### 5.4.2 **Prototype Networks –¥–ª—è PU**

- –ü—Ä–æ—Ç–æ—Ç–∏–ø—ã –¥–ª—è P –∫–ª–∞—Å—Å–∞
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ N –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤
- Few-shot learning –∞–¥–∞–ø—Ç–∞—Ü–∏—è

### 5.5 üé≠ Ensemble –∏ –≥–∏–±—Ä–∏–¥–Ω—ã–µ –º–µ—Ç–æ–¥—ã

#### 5.5.1 **Multi-view PU Learning**

- –†–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- –ö–æ–Ω—Å–µ–Ω—Å—É—Å –º–µ–∂–¥—É views
- Co-regularization: `L = L_view1 + L_view2 + Œª√óconsistency`

#### 5.5.2 **Cost-sensitive PU Learning**

- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –æ—à–∏–±–æ–∫
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫
- ROI-driven –ø–æ–¥—Ö–æ–¥

---

## 6. üß™ –ü–ª–∞–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### 6.1 –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```mermaid
graph LR
    A[–î–∞—Ç–∞—Å–µ—Ç—ã] --> B[PU –°–∏–º—É–ª—è—Ü–∏—è]
    B --> C[Baseline]
    B --> D[–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ PU]
    B --> E[–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ PU]
    C --> F[–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    D --> F
    E --> F
```

### 6.2 üéõÔ∏è –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

#### **Optuna** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞:

```python
study = optuna.create_study(
    directions=["maximize", "minimize"],  # F1-score, –≤—Ä–µ–º—è
    sampler=TPESampler(),
    pruner=MedianPruner()
)

study.optimize(
    objective,
    n_trials=100,
    timeout=7200,  # 2 —á–∞—Å–∞
    n_jobs=-1  # –í—Å–µ CPU
)
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:
- üéØ Multi-objective –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- ‚è±Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª—å –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ timeout
- üîÑ Warm start —Å –ø–æ—Ö–æ–∂–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- üå± Fixed random seeds

---

## üìö –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

1. **Elkan & Noto (2008)**: "Learning classifiers from only positive and unlabeled data"
2. **du Plessis et al. (2015)**: "Analysis of learning from positive and unlabeled data"
3. **Kiryo et al. (2017)**: "Positive-unlabeled learning with non-negative risk estimator"
4. **Bekker & Davis (2020)**: "Learning from positive and unlabeled data: a survey"

---

> üìß **–ö–æ–Ω—Ç–∞–∫—Ç—ã**: [dmatryus.sqrt49@yandex.ru]  
> üîó **GitHub**: [[–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/Dmatryus/DmDSLab)]  
> üìÖ **–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025