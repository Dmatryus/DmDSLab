#!/usr/bin/env python3
"""
One-click benchmark script - –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ Pandas vs Polars –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python one_click_benchmark.py              # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (5 –º–∏–Ω—É—Ç)
    python one_click_benchmark.py --medium     # –°—Ä–µ–¥–Ω–∏–π —Ç–µ—Å—Ç (30 –º–∏–Ω—É—Ç)
    python one_click_benchmark.py --full       # –ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç (2+ —á–∞—Å–∞)
    python one_click_benchmark.py --tiny       # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç (2 –º–∏–Ω—É—Ç—ã)
"""

import argparse
import subprocess
import sys
import yaml
from pathlib import Path
from datetime import datetime


def create_config(test_size='quick'):
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ—Å—Ç–∞."""
    
    configs = {
        'tiny': {
            'name': 'Tiny Test (2 minutes)',
            'sizes': [500, 1000],
            'operations': {
                'io': ['read_csv'],
                'filter': ['simple_filter'],
                'groupby': ['single_column_groupby']
            },
            'min_runs': 3,
            'max_runs': 5,
            'columns': 3
        },
        'quick': {
            'name': 'Quick Test (5 minutes)',
            'sizes': [1000, 5000, 10000],
            'operations': {
                'io': ['read_csv', 'write_csv'],
                'filter': ['simple_filter', 'complex_filter'],
                'groupby': ['single_column_groupby', 'multi_aggregation'],
                'sort': ['single_column_sort']
            },
            'min_runs': 3,
            'max_runs': 10,
            'columns': 5
        },
        'medium': {
            'name': 'Medium Test (30 minutes)',
            'sizes': [10000, 50000, 100000],
            'operations': {
                'io': ['read_csv', 'write_csv', 'read_parquet', 'write_parquet'],
                'filter': ['simple_filter', 'complex_filter', 'isin_filter'],
                'groupby': ['single_column_groupby', 'multi_column_groupby', 'multi_aggregation'],
                'sort': ['single_column_sort', 'multi_column_sort'],
                'join': ['inner_join', 'left_join']
            },
            'min_runs': 5,
            'max_runs': 20,
            'columns': 10
        },
        'full': {
            'name': 'Full Test (2+ hours)',
            'sizes': [10000, 100000, 1000000],
            'operations': {
                'io': ['read_csv', 'write_csv', 'read_parquet', 'write_parquet'],
                'filter': ['simple_filter', 'complex_filter', 'isin_filter', 'pattern_filter'],
                'groupby': ['single_column_groupby', 'multi_column_groupby', 'multi_aggregation', 'window_functions'],
                'sort': ['single_column_sort', 'multi_column_sort', 'custom_sort'],
                'join': ['inner_join', 'left_join', 'multi_key_join', 'asof_join'],
                'string': ['contains_operation', 'replace_operation', 'extract_operation']
            },
            'min_runs': 5,
            'max_runs': 50,
            'columns': 20
        }
    }
    
    config_data = configs[test_size]
    
    return {
        'benchmark': {
            'name': config_data['name'],
            'version': '1.0.0',
            'description': f'Automated {test_size} benchmark run'
        },
        'environment': {
            'seed': 42
        },
        'data_generation': {
            'sizes': config_data['sizes'],
            'datasets': {
                'numeric': {
                    'enabled': True,
                    'columns': config_data['columns']
                },
                'string': {
                    'enabled': test_size in ['medium', 'full'],
                    'columns': max(3, config_data['columns'] // 2)
                },
                'mixed': {
                    'enabled': test_size == 'full',
                    'numeric_columns': config_data['columns'] // 2,
                    'string_columns': config_data['columns'] // 4
                }
            }
        },
        'operations': config_data['operations'],
        'profiling': {
            'min_runs': config_data['min_runs'],
            'max_runs': config_data['max_runs'],
            'target_cv': 0.05 if test_size == 'full' else 0.1,
            'warmup_runs': 1 if test_size in ['tiny', 'quick'] else 2
        },
        'output': {
            'generate_plots': True,
            'create_report': True,
            'save_raw_results': True
        }
    }


def check_environment():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É."""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –≤–µ—Ä—Å–∏–∏
    if sys.version_info < (3, 11):
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.11 –∏–ª–∏ –≤—ã—à–µ")
        print(f"   –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è: {sys.version}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
    required_modules = ['pandas', 'polars', 'plotly', 'numpy', 'yaml']
    missing_modules = []
    
    for module in required_modules:
        try:
            __import__(module)
        except ImportError:
            missing_modules.append(module)
    
    if missing_modules:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏:")
        for module in missing_modules:
            print(f"   - {module}")
        print("\nüí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–æ–º–∞–Ω–¥–æ–π:")
        print("   pip install -r requirements.txt")
        return False
    
    print("‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ")
    return True


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(
        description='–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ Pandas vs Polars –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π'
    )
    parser.add_argument(
        '--tiny', action='store_true',
        help='–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç (2 –º–∏–Ω—É—Ç—ã)'
    )
    parser.add_argument(
        '--medium', action='store_true',
        help='–°—Ä–µ–¥–Ω–∏–π —Ç–µ—Å—Ç (30 –º–∏–Ω—É—Ç)'
    )
    parser.add_argument(
        '--full', action='store_true',
        help='–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç (2+ —á–∞—Å–∞)'
    )
    parser.add_argument(
        '--output-dir', type=str, default=None,
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ—Å—Ç–∞
    if args.tiny:
        test_size = 'tiny'
    elif args.medium:
        test_size = 'medium'
    elif args.full:
        test_size = 'full'
    else:
        test_size = 'quick'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not check_environment():
        sys.exit(1)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    config_path = Path(f'configs/auto_config_{test_size}_{timestamp}.yaml')
    
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ {test_size.upper()} –±–µ–Ω—á–º–∞—Ä–∫–∞")
    print(f"üìù –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_path.parent.mkdir(exist_ok=True)
    config = create_config(test_size)
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, sort_keys=False)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–º–∞–Ω–¥—ã –∑–∞–ø—É—Å–∫–∞
    cmd = [
        sys.executable,
        'scripts/run_benchmark.py',
        '--config', str(config_path)
    ]
    
    if args.output_dir:
        cmd.extend(['--output-dir', args.output_dir])
    
    # –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞
    print(f"üèÉ –ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: {' '.join(cmd)}")
    print("-" * 80)
    
    try:
        result = subprocess.run(cmd, check=True)
        
        print("\n" + "=" * 80)
        print("‚úÖ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        print("=" * 80)
        
        # –ü–æ–∏—Å–∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report_pattern = "results/reports/benchmark_report_*.html"
        if args.output_dir:
            report_pattern = f"{args.output_dir}/reports/benchmark_report_*.html"
        
        report_files = list(Path(".").glob(report_pattern))
        if report_files:
            latest_report = max(report_files, key=lambda p: p.stat().st_mtime)
            print(f"\nüìä –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {latest_report}")
            print(f"üí° –û—Ç–∫—Ä–æ–π—Ç–µ –≤ –±—Ä–∞—É–∑–µ—Ä–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫—Ä—ã—Ç—å –æ—Ç—á–µ—Ç
            if sys.platform == 'darwin':  # macOS
                subprocess.run(['open', str(latest_report)])
            elif sys.platform == 'win32':  # Windows
                subprocess.run(['start', '', str(latest_report)], shell=True)
            elif sys.platform.startswith('linux'):  # Linux
                subprocess.run(['xdg-open', str(latest_report)])
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_path.unlink()
        
    except subprocess.CalledProcessError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'python scripts/run_benchmark.py --resume' –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è")
        sys.exit(1)


if __name__ == '__main__':
    main()
